{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"-RHCio2xl7Fe","execution":{"iopub.status.busy":"2022-06-25T13:35:17.524859Z","iopub.execute_input":"2022-06-25T13:35:17.525451Z","iopub.status.idle":"2022-06-25T13:35:17.529994Z","shell.execute_reply.started":"2022-06-25T13:35:17.525414Z","shell.execute_reply":"2022-06-25T13:35:17.528859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage\nimport multiprocessing as mp\nimport os\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torchvision.models import resnet18\nfrom torchvision.models import ResNet\n","metadata":{"id":"VcQjNEilZ1Jx","execution":{"iopub.status.busy":"2022-06-25T13:35:19.797047Z","iopub.execute_input":"2022-06-25T13:35:19.797395Z","iopub.status.idle":"2022-06-25T13:35:19.803917Z","shell.execute_reply.started":"2022-06-25T13:35:19.797366Z","shell.execute_reply":"2022-06-25T13:35:19.802693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset='../input/miniimagenet'\n","metadata":{"id":"belOyWDs06rg","outputId":"73952877-e512-4672-b7eb-d54f602f251d","execution":{"iopub.status.busy":"2022-06-25T13:35:26.805869Z","iopub.execute_input":"2022-06-25T13:35:26.806244Z","iopub.status.idle":"2022-06-25T13:35:26.81102Z","shell.execute_reply.started":"2022-06-25T13:35:26.80621Z","shell.execute_reply":"2022-06-25T13:35:26.809974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n","metadata":{"id":"66E0XWRBTP7Y","execution":{"iopub.status.busy":"2022-06-25T13:35:34.995446Z","iopub.execute_input":"2022-06-25T13:35:34.995892Z","iopub.status.idle":"2022-06-25T13:35:35.001665Z","shell.execute_reply.started":"2022-06-25T13:35:34.995853Z","shell.execute_reply":"2022-06-25T13:35:35.000095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just needed in case you'd like to append it to an array\ndata = []\nlabel=[]\nfor filename in os.listdir(dataset): \n        # Your code comes here such as \n    #print(filename)\n    indata=[]\n    inlabel=[]\n    filepath=dataset+'/'+filename\n    for i in os.listdir(filepath):\n      \n      img_path=filepath+'/'+i\n      img = Image.open(img_path)\n      img=img.resize((40, 40))\n      img_as_array = np.array(img)\n      #print(img_as_array.shape)\n      if(img_as_array.shape==(40,40)):\n        #print(img_as_array.shape)\n        img_as_array=np.stack((img_as_array,)*3, axis=-1)\n        #print(img_as_array.shape)\n      indata.append(img_as_array[:,:,:3])\n      \n     \n    data.append(indata)\n    inlabel=[filename]*600\n    inlabel=np.array(inlabel)\n    label.append(inlabel)\n","metadata":{"id":"61NvCVjLPpM5","execution":{"iopub.status.busy":"2022-06-25T13:35:35.685795Z","iopub.execute_input":"2022-06-25T13:35:35.68643Z","iopub.status.idle":"2022-06-25T13:46:27.759435Z","shell.execute_reply.started":"2022-06-25T13:35:35.686391Z","shell.execute_reply":"2022-06-25T13:46:27.758187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Fn2en0hXlbEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdata=[]\nfor i in data:\n  i=np.array(i)\n  newdata.append(i)\nnewdata=np.array(newdata)","metadata":{"id":"9O_0T5DMzhjQ","execution":{"iopub.status.busy":"2022-06-25T13:46:27.761143Z","iopub.execute_input":"2022-06-25T13:46:27.761501Z","iopub.status.idle":"2022-06-25T13:46:28.078455Z","shell.execute_reply.started":"2022-06-25T13:46:27.761461Z","shell.execute_reply":"2022-06-25T13:46:28.077373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(newdata)","metadata":{"id":"BuV_qKZT0z-P","outputId":"d2216b42-46bb-4284-c439-68138f3d2108","execution":{"iopub.status.busy":"2022-06-25T13:46:28.080211Z","iopub.execute_input":"2022-06-25T13:46:28.080588Z","iopub.status.idle":"2022-06-25T13:46:28.105482Z","shell.execute_reply.started":"2022-06-25T13:46:28.080541Z","shell.execute_reply":"2022-06-25T13:46:28.104613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdata.shape","metadata":{"id":"BYTYLf2U02_6","outputId":"e0777f0b-0af9-4dd3-dfcf-f0ed83757f4c","execution":{"iopub.status.busy":"2022-06-25T13:46:28.108245Z","iopub.execute_input":"2022-06-25T13:46:28.108583Z","iopub.status.idle":"2022-06-25T13:46:28.117427Z","shell.execute_reply.started":"2022-06-25T13:46:28.108541Z","shell.execute_reply":"2022-06-25T13:46:28.115363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdata=newdata.reshape(60000,40,40,3)\nnewdata","metadata":{"id":"r3jQVu_U2G7B","outputId":"fac49b36-cf6c-415b-e79a-8f15f0f9c9c8","execution":{"iopub.status.busy":"2022-06-25T13:46:28.119332Z","iopub.execute_input":"2022-06-25T13:46:28.120139Z","iopub.status.idle":"2022-06-25T13:46:28.133916Z","shell.execute_reply.started":"2022-06-25T13:46:28.120102Z","shell.execute_reply":"2022-06-25T13:46:28.133093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdata=newdata/255\nnewdata","metadata":{"id":"iVJsr2lRmIHp","outputId":"a2fbd6dc-fdeb-4673-b00a-b0cecb64c202","execution":{"iopub.status.busy":"2022-06-25T13:46:28.135261Z","iopub.execute_input":"2022-06-25T13:46:28.135678Z","iopub.status.idle":"2022-06-25T13:46:29.124354Z","shell.execute_reply.started":"2022-06-25T13:46:28.135643Z","shell.execute_reply":"2022-06-25T13:46:29.123389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdata.shape","metadata":{"id":"r-qq0b0o2atq","outputId":"6884e9d6-828b-434d-f4b5-1d58b79b26d1","execution":{"iopub.status.busy":"2022-06-25T13:46:29.125617Z","iopub.execute_input":"2022-06-25T13:46:29.128242Z","iopub.status.idle":"2022-06-25T13:46:29.134635Z","shell.execute_reply.started":"2022-06-25T13:46:29.128196Z","shell.execute_reply":"2022-06-25T13:46:29.133608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label=np.array(label)\nlabel=label.reshape(60000)\nlabel","metadata":{"id":"kjZ-2SO71oxC","outputId":"c32c0c17-6eb8-40e0-db6f-9758d708d9ac","execution":{"iopub.status.busy":"2022-06-25T13:46:29.136366Z","iopub.execute_input":"2022-06-25T13:46:29.136805Z","iopub.status.idle":"2022-06-25T13:46:29.147596Z","shell.execute_reply.started":"2022-06-25T13:46:29.136769Z","shell.execute_reply":"2022-06-25T13:46:29.146433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hRE3zpSe0VaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('/content/drive/MyDrive/Xdata',newdata)\nnp.save('/content/drive/MyDrive/ydata',label)","metadata":{"id":"fSH1HrYKwfZV","outputId":"c7ada803-240e-41d7-f721-4876204b3fa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.load('/content/drive/MyDrive/Xdata.npy')\ny=np.load('/content/drive/MyDrive/ydata.npy')\nX.shape,y.shape","metadata":{"id":"MsZ4JjzK01Nl","outputId":"b3755939-ce60-477c-d986-881c227ed559"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtrain, Xtest, ytrain, ytest = train_test_split(newdata, label, test_size=0.2)","metadata":{"id":"RTrVtCo-MJM8","execution":{"iopub.status.busy":"2022-06-25T13:46:29.149595Z","iopub.execute_input":"2022-06-25T13:46:29.149987Z","iopub.status.idle":"2022-06-25T13:46:32.172552Z","shell.execute_reply.started":"2022-06-25T13:46:29.149951Z","shell.execute_reply":"2022-06-25T13:46:32.171565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)","metadata":{"id":"AfooV0WQMcLa","execution":{"iopub.status.busy":"2022-06-25T13:46:32.17725Z","iopub.execute_input":"2022-06-25T13:46:32.177882Z","iopub.status.idle":"2022-06-25T13:46:34.335225Z","shell.execute_reply.started":"2022-06-25T13:46:32.17785Z","shell.execute_reply":"2022-06-25T13:46:34.334256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)","metadata":{"id":"gIWjnsmQ-miA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nXtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2)","metadata":{"id":"Hrlh-87r-miP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain.shape","metadata":{"id":"gf2nk5XkMiIy","outputId":"61f0c090-1412-497e-bf1c-2c03ddbd5ce1","execution":{"iopub.status.busy":"2022-06-25T13:46:34.336833Z","iopub.execute_input":"2022-06-25T13:46:34.337213Z","iopub.status.idle":"2022-06-25T13:46:34.344208Z","shell.execute_reply.started":"2022-06-25T13:46:34.337174Z","shell.execute_reply":"2022-06-25T13:46:34.343191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"id":"OasW_4eZbTyJ","outputId":"ec8cf798-a1fa-4c8f-d48b-dad940805816","execution":{"iopub.status.busy":"2022-06-25T13:46:34.34617Z","iopub.execute_input":"2022-06-25T13:46:34.346931Z","iopub.status.idle":"2022-06-25T13:46:34.426211Z","shell.execute_reply.started":"2022-06-25T13:46:34.34689Z","shell.execute_reply":"2022-06-25T13:46:34.424996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainx, trainy = Xtrain,ytrain","metadata":{"id":"1e_TPvejXdrU","execution":{"iopub.status.busy":"2022-06-25T13:46:34.429823Z","iopub.execute_input":"2022-06-25T13:46:34.430367Z","iopub.status.idle":"2022-06-25T13:46:34.436284Z","shell.execute_reply.started":"2022-06-25T13:46:34.430317Z","shell.execute_reply":"2022-06-25T13:46:34.434947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testx, testy = Xtest,ytest","metadata":{"id":"Ow3n7IafXf36","execution":{"iopub.status.busy":"2022-06-25T13:46:34.439101Z","iopub.execute_input":"2022-06-25T13:46:34.439924Z","iopub.status.idle":"2022-06-25T13:46:34.447643Z","shell.execute_reply.started":"2022-06-25T13:46:34.439884Z","shell.execute_reply":"2022-06-25T13:46:34.446467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valx,valy=Xval,yval","metadata":{"id":"2Brk5qmljifi","execution":{"iopub.status.busy":"2022-06-25T13:46:34.4492Z","iopub.execute_input":"2022-06-25T13:46:34.449737Z","iopub.status.idle":"2022-06-25T13:46:34.458177Z","shell.execute_reply.started":"2022-06-25T13:46:34.449699Z","shell.execute_reply":"2022-06-25T13:46:34.457243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainx.shape, trainy.shape, testx.shape, testy.shape","metadata":{"id":"r3FUB_nabnX7","outputId":"9e393801-9554-4494-ce94-6bb0d65cabe5","execution":{"iopub.status.busy":"2022-06-25T13:46:34.459401Z","iopub.execute_input":"2022-06-25T13:46:34.460364Z","iopub.status.idle":"2022-06-25T13:46:34.470411Z","shell.execute_reply.started":"2022-06-25T13:46:34.460327Z","shell.execute_reply":"2022-06-25T13:46:34.469365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"WKfgm2pdZM0V","execution":{"iopub.status.busy":"2022-06-25T13:46:34.471783Z","iopub.execute_input":"2022-06-25T13:46:34.472188Z","iopub.status.idle":"2022-06-25T13:46:34.479318Z","shell.execute_reply.started":"2022-06-25T13:46:34.472153Z","shell.execute_reply":"2022-06-25T13:46:34.478427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_sample(n_way, n_support, n_query, datax, datay):\n  \"\"\"\n  Picks random sample of size n_support+n_querry, for n_way classes\n  Args:\n      n_way (int): number of classes in a classification task\n      n_support (int): number of labeled examples per class in the support set\n      n_query (int): number of labeled examples per class in the query set\n      datax (np.array): dataset of images\n      datay (np.array): dataset of labels\n  Returns:\n      (dict) of:\n        (torch.Tensor): sample of images. Size (n_way, n_support+n_query, (dim))\n        (int): n_way\n        (int): n_support\n        (int): n_query\n  \"\"\"\n  sample = []\n  K = np.random.choice(np.unique(datay), n_way, replace=False)\n  for cls in K:\n    datax_cls = datax[datay == cls]\n    perm = np.random.permutation(datax_cls)\n    sample_cls = perm[:(n_support+n_query)]\n    sample.append(sample_cls)\n  sample = np.array(sample)\n  sample = torch.from_numpy(sample).float()\n  sample = sample.permute(0,1,4,2,3)\n  return({\n      'images': sample,\n      'n_way': n_way,\n      'n_support': n_support,\n      'n_query': n_query\n      })","metadata":{"id":"IDXnRB30bo1F","execution":{"iopub.status.busy":"2022-06-25T13:46:34.480847Z","iopub.execute_input":"2022-06-25T13:46:34.481261Z","iopub.status.idle":"2022-06-25T13:46:34.49113Z","shell.execute_reply.started":"2022-06-25T13:46:34.481223Z","shell.execute_reply":"2022-06-25T13:46:34.489801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_sample(sample):\n  \"\"\"\n  Displays sample in a grid\n  Args:\n      sample (torch.Tensor): sample of images to display\n  \"\"\"\n  #need 4D tensor to create grid, currently 5D\n  sample_4D = sample.view(sample.shape[0]*sample.shape[1],*sample.shape[2:])\n  #make a grid\n  out = torchvision.utils.make_grid(sample_4D, nrow=sample.shape[1])\n  plt.figure(figsize = (16,7))\n  plt.imshow(out.permute(1, 2, 0))","metadata":{"id":"7CnTh_CObq59","execution":{"iopub.status.busy":"2022-06-25T13:46:34.492844Z","iopub.execute_input":"2022-06-25T13:46:34.493388Z","iopub.status.idle":"2022-06-25T13:46:34.502806Z","shell.execute_reply.started":"2022-06-25T13:46:34.493352Z","shell.execute_reply":"2022-06-25T13:46:34.501916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_example = extract_sample(8, 5, 5, trainx, trainy)\ndisplay_sample(sample_example['images'])","metadata":{"id":"6NeLv3FdbsyN","outputId":"13ade68a-e110-469d-cc1d-e93242af5e73","execution":{"iopub.status.busy":"2022-06-25T13:46:34.505977Z","iopub.execute_input":"2022-06-25T13:46:34.506281Z","iopub.status.idle":"2022-06-25T13:46:34.914615Z","shell.execute_reply.started":"2022-06-25T13:46:34.506253Z","shell.execute_reply":"2022-06-25T13:46:34.91201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"b5AuV4n6jERg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SE_Block(nn.Module):\n    \"credits: https://github.com/moskomule/senet.pytorch/blob/master/senet/se_module.py#L4\"\n    def __init__(self, c, r=16):\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool2d(1)\n        self.excitation = nn.Sequential(\n            nn.Linear(c, c // r, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(c // r, c, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        bs, c, _, _ = x.shape\n        y = self.squeeze(x).view(bs, c)\n        y = self.excitation(y).view(bs, c, 1, 1)\n        return x * y.expand_as(x)","metadata":{"id":"R9h6Zdp3gOWX","execution":{"iopub.status.busy":"2022-06-25T13:46:34.915742Z","iopub.execute_input":"2022-06-25T13:46:34.916207Z","iopub.status.idle":"2022-06-25T13:46:34.926951Z","shell.execute_reply.started":"2022-06-25T13:46:34.91617Z","shell.execute_reply":"2022-06-25T13:46:34.925779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UzIO3NuiLryJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\ndef _resnet(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    return model","metadata":{"id":"QC0VI_jjgFxm","execution":{"iopub.status.busy":"2022-06-25T13:46:34.928994Z","iopub.execute_input":"2022-06-25T13:46:34.929815Z","iopub.status.idle":"2022-06-25T13:46:34.938697Z","shell.execute_reply.started":"2022-06-25T13:46:34.929777Z","shell.execute_reply":"2022-06-25T13:46:34.937729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"id":"p44uAM3gm3AI","outputId":"73be2719-19da-4801-d26b-2ac80946f008"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nmodel = timm.create_model('seresnet101', pretrained=True)","metadata":{"id":"w3UNObCfmTPM","outputId":"53dda8c4-0545-4524-ff8b-e9cf4a053a65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def se_resnet18(pretrained=False, progress=True, **kwargs):\n    return _resnet('resnet18', SEBasicBlock, [2,2,2,2], pretrained, progress,\n                   **kwargs)","metadata":{"id":"NSO9xrccge2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def se_resnet34(pretrained=False, progress=True, **kwargs):\n    return _resnet('resnet34', SEBasicBlock, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)","metadata":{"id":"yOAHtvG95BPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn.parameter import Parameter\n\nclass eca_layer(nn.Module):\n    \"\"\"Constructs a ECA module.\n    Args:\n        channel: Number of channels of the input feature map\n        k_size: Adaptive selection of kernel size\n    \"\"\"\n    def __init__(self, channel, k_size=3):\n        super(eca_layer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # feature descriptor on the global spatial information\n        y = self.avg_pool(x)\n\n        # Two different branches of ECA module\n        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n\n        # Multi-scale information fusion\n        y = self.sigmoid(y)\n\n        return x * y.expand_as(x)","metadata":{"id":"y0FT6g1ML-YM","execution":{"iopub.status.busy":"2022-06-25T13:46:34.939685Z","iopub.execute_input":"2022-06-25T13:46:34.939942Z","iopub.status.idle":"2022-06-25T13:46:34.953308Z","shell.execute_reply.started":"2022-06-25T13:46:34.939898Z","shell.execute_reply":"2022-06-25T13:46:34.952419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport math\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicConv(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n        super(BasicConv, self).__init__()\n        self.out_channels = out_planes\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n        self.relu = nn.ReLU() if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\nclass ChannelGate(nn.Module):\n    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n        super(ChannelGate, self).__init__()\n        self.gate_channels = gate_channels\n        self.mlp = nn.Sequential(\n            Flatten(),\n            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n            nn.ReLU(),\n            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n            )\n        self.pool_types = pool_types\n    def forward(self, x):\n        channel_att_sum = None\n        for pool_type in self.pool_types:\n            if pool_type=='avg':\n                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp( avg_pool )\n            elif pool_type=='max':\n                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp( max_pool )\n            elif pool_type=='lp':\n                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n                channel_att_raw = self.mlp( lp_pool )\n            elif pool_type=='lse':\n                # LSE pool only\n                lse_pool = logsumexp_2d(x)\n                channel_att_raw = self.mlp( lse_pool )\n\n            if channel_att_sum is None:\n                channel_att_sum = channel_att_raw\n            else:\n                channel_att_sum = channel_att_sum + channel_att_raw\n\n        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n        return x * scale\n\ndef logsumexp_2d(tensor):\n    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n    return outputs\n\nclass ChannelPool(nn.Module):\n    def forward(self, x):\n        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n\nclass SpatialGate(nn.Module):\n    def __init__(self):\n        super(SpatialGate, self).__init__()\n        kernel_size = 7\n        self.compress = ChannelPool()\n        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n    def forward(self, x):\n        x_compress = self.compress(x)\n        x_out = self.spatial(x_compress)\n        scale = F.sigmoid(x_out) # broadcasting\n        return x * scale\n\nclass CBAM(nn.Module):\n    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n        super(CBAM, self).__init__()\n        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n        self.no_spatial=no_spatial\n        if not no_spatial:\n            self.SpatialGate = SpatialGate()\n    def forward(self, x):\n        x_out = self.ChannelGate(x)\n        if not self.no_spatial:\n            x_out = self.SpatialGate(x_out)\n        return x_out","metadata":{"id":"Loid1Dc2t1az","execution":{"iopub.status.busy":"2022-06-25T13:46:34.956604Z","iopub.execute_input":"2022-06-25T13:46:34.95688Z","iopub.status.idle":"2022-06-25T13:46:34.98392Z","shell.execute_reply.started":"2022-06-25T13:46:34.956853Z","shell.execute_reply":"2022-06-25T13:46:34.982965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Flatten(nn.Module):\n  def __init__(self):\n    super(Flatten, self).__init__()\n\n  def forward(self, x):\n    return x.view(x.size(0), -1)\n\ndef load_protonet_conv_se(**kwargs):\n  \"\"\"\n  Loads the prototypical network model\n  Arg:\n      x_dim (tuple): dimension of input image\n      hid_dim (int): dimension of hidden layers in conv blocks\n      z_dim (int): dimension of embedded image\n  Returns:\n      Model (Class ProtoNet)\n  \"\"\"\n  x_dim = kwargs['x_dim']\n  hid_dim = kwargs['hid_dim']\n  z_dim = kwargs['z_dim']\n\n  def conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_se(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        SE_Block(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_eca(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        eca_layer(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  encoder = nn.Sequential(\n    conv_block(x_dim[0], hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block_se(hid_dim, z_dim),\n    Flatten()\n    )\n    \n  return ProtoNet(encoder)\n\ndef load_protonet_conv_eca(**kwargs):\n  \"\"\"\n  Loads the prototypical network model\n  Arg:\n      x_dim (tuple): dimension of input image\n      hid_dim (int): dimension of hidden layers in conv blocks\n      z_dim (int): dimension of embedded image\n  Returns:\n      Model (Class ProtoNet)\n  \"\"\"\n  x_dim = kwargs['x_dim']\n  hid_dim = kwargs['hid_dim']\n  z_dim = kwargs['z_dim']\n\n  def conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_se(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        SE_Block(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_eca(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        eca_layer(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  encoder = nn.Sequential(\n    conv_block(x_dim[0], hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block_eca(hid_dim, z_dim),\n    Flatten()\n    )\n    \n  return ProtoNet(encoder)\n\n\ndef load_protonet_conv_cbam(**kwargs):\n  \"\"\"\n  Loads the prototypical network model\n  Arg:\n      x_dim (tuple): dimension of input image\n      hid_dim (int): dimension of hidden layers in conv blocks\n      z_dim (int): dimension of embedded image\n  Returns:\n      Model (Class ProtoNet)\n  \"\"\"\n  x_dim = kwargs['x_dim']\n  hid_dim = kwargs['hid_dim']\n  z_dim = kwargs['z_dim']\n\n  def conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_se(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        SE_Block(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_eca(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        eca_layer(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_cbam(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        CBAM(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  encoder = nn.Sequential(\n    conv_block(x_dim[0], hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block_eca(hid_dim, z_dim),\n    Flatten()\n    )\n    \n  return ProtoNet(encoder)\n\ndef load_protonet_conv(**kwargs):\n  \"\"\"\n  Loads the prototypical network model\n  Arg:\n      x_dim (tuple): dimension of input image\n      hid_dim (int): dimension of hidden layers in conv blocks\n      z_dim (int): dimension of embedded image\n  Returns:\n      Model (Class ProtoNet)\n  \"\"\"\n  x_dim = kwargs['x_dim']\n  hid_dim = kwargs['hid_dim']\n  z_dim = kwargs['z_dim']\n\n  def conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  def conv_block_se(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        SE_Block(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n  encoder = nn.Sequential(\n    conv_block(x_dim[0], hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, z_dim),\n    Flatten()\n    )\n    \n  return ProtoNet(encoder)","metadata":{"id":"2yxyClam6e1_","execution":{"iopub.status.busy":"2022-06-25T13:46:34.985698Z","iopub.execute_input":"2022-06-25T13:46:34.986057Z","iopub.status.idle":"2022-06-25T13:46:35.137987Z","shell.execute_reply.started":"2022-06-25T13:46:34.986014Z","shell.execute_reply":"2022-06-25T13:46:35.137004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nclass Flatten(nn.Module):\n  def __init__(self):\n    super(Flatten, self).__init__()\n\n  def forward(self, x):\n    return x.view(x.size(0), -1)\n\ndef load_protonet_conv(arg=18):\n  \"\"\"\n  Loads the prototypical network model\n  Arg:\n      x_dim (tuple): dimension of input image\n      hid_dim (int): dimension of hidden layers in conv blocks\n      z_dim (int): dimension of embedded image\n  Returns:\n      Model (Class ProtoNet)\n  \"\"\"\n  \"\"\"x_dim = kwargs['x_dim']\n  hid_dim = kwargs['hid_dim']\n  z_dim = kwargs['z_dim']\"\"\"\n\n  \"\"\"def conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n        )\n    \n  encoder = nn.Sequential(\n    conv_block(x_dim[0], hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, hid_dim),\n    conv_block(hid_dim, z_dim),\n    Flatten()\n    )\"\"\"\n  if arg==18:\n    convolutional_network = se_resnet18(pretrained=True)\n    convolutional_network.fc = nn.Flatten()  \n    return ProtoNet(convolutional_network)\n  \n  if arg==34:\n    convolutional_network = se_resnet34(pretrained=True)\n    convolutional_network.fc = nn.Flatten()  \n    return ProtoNet(convolutional_network)\n\n  if arg==101:\n    convolutional_network = timm.create_model('seresnet101', pretrained=True)\n    convolutional_network.fc = nn.Flatten()  \n    return ProtoNet(convolutional_network)\n    \n  if arg==152:\n    convolutional_network = timm.create_model('seresnet152', pretrained=True)\n    convolutional_network.fc = nn.Flatten()  \n    return ProtoNet(convolutional_network)\n    \"\"\"","metadata":{"id":"dea5uoosbudt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProtoNet(nn.Module):\n  def __init__(self, encoder):\n    \"\"\"\n    Args:\n        encoder : CNN encoding the images in sample\n        n_way (int): number of classes in a classification task\n        n_support (int): number of labeled examples per class in the support set\n        n_query (int): number of labeled examples per class in the query set\n    \"\"\"\n    super(ProtoNet, self).__init__()\n    self.encoder = encoder.cuda()\n    #self.encoder=encoder\n\n  def set_forward_loss(self, sample):\n    \"\"\"\n    Computes loss, accuracy and output for classification task\n    Args:\n        sample (torch.Tensor): shape (n_way, n_support+n_query, (dim)) \n    Returns:\n        torch.Tensor: shape(2), loss, accuracy and y_hat\n    \"\"\"\n    sample_images = sample['images'].cuda()\n    #sample_images=sample['images']\n    n_way = sample['n_way']\n    n_support = sample['n_support']\n    n_query = sample['n_query']\n\n    x_support = sample_images[:, :n_support]\n    x_query = sample_images[:, n_support:]\n   \n    #target indices are 0 ... n_way-1\n    target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n    target_inds = Variable(target_inds, requires_grad=False)\n    target_inds = target_inds.cuda()\n    \n   \n    #encode images of the support and the query set\n    x = torch.cat([x_support.contiguous().view(n_way * n_support, *x_support.size()[2:]),\n                   x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])], 0)\n   \n    z = self.encoder.forward(x)\n    z_dim = z.size(-1) #usually 64\n    z_proto = z[:n_way*n_support].view(n_way, n_support, z_dim).mean(1)\n    z_query = z[n_way*n_support:]\n\n    #compute distances\n    dists = euclidean_dist(z_query, z_proto)\n    \n    #compute probabilities\n    log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n   \n    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n    _, y_hat = log_p_y.max(2)\n    acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n   \n    return loss_val, {\n        'loss': loss_val.item(),\n        'acc': acc_val.item(),\n        'y_hat': y_hat\n        }","metadata":{"id":"YCrRopd9b4Hh","execution":{"iopub.status.busy":"2022-06-25T13:46:35.139768Z","iopub.execute_input":"2022-06-25T13:46:35.14024Z","iopub.status.idle":"2022-06-25T13:46:35.159259Z","shell.execute_reply.started":"2022-06-25T13:46:35.140201Z","shell.execute_reply":"2022-06-25T13:46:35.158208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def euclidean_dist(x, y):\n  \"\"\"\n  Computes euclidean distance btw x and y\n  Args:\n      x (torch.Tensor): shape (n, d). n usually n_way*n_query\n      y (torch.Tensor): shape (m, d). m usually n_way\n  Returns:\n      torch.Tensor: shape(n, m). For each query, the distances to each centroid\n  \"\"\"\n  n = x.size(0)\n  m = y.size(0)\n  d = x.size(1)\n  assert d == y.size(1)\n\n  x = x.unsqueeze(1).expand(n, m, d)\n  y = y.unsqueeze(0).expand(n, m, d)\n\n  return torch.pow(x - y, 2).sum(2)","metadata":{"id":"PfiBbMEjb4lt","execution":{"iopub.status.busy":"2022-06-25T13:46:35.160723Z","iopub.execute_input":"2022-06-25T13:46:35.16154Z","iopub.status.idle":"2022-06-25T13:46:35.171475Z","shell.execute_reply.started":"2022-06-25T13:46:35.161501Z","shell.execute_reply":"2022-06-25T13:46:35.170514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm_notebook\nfrom tqdm import tnrange","metadata":{"id":"ONNwWDpIb6Yn","execution":{"iopub.status.busy":"2022-06-25T13:46:35.177747Z","iopub.execute_input":"2022-06-25T13:46:35.179151Z","iopub.status.idle":"2022-06-25T13:46:35.18486Z","shell.execute_reply.started":"2022-06-25T13:46:35.179062Z","shell.execute_reply":"2022-06-25T13:46:35.183984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ITd3ZgR86zrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_MIN(model, optimizer, train_x, train_y,val_x,val_y, n_way, n_support, n_query, epoch_size):\n  \"\"\"\n  Trains the protonet\n  Args:\n      model\n      optimizer\n      train_x (np.array): images of training set\n      train_y(np.array): labels of training set\n      n_way (int): number of classes in a classification task\n      n_support (int): number of labeled examples per class in the support set\n      n_query (int): number of labeled examples per class in the query set\n      max_epoch (int): max epochs to train on\n      epoch_size (int): episodes per epoch\n  \"\"\"\n  #divide the learning rate by 2 at each epoch, as suggested in paper\n  scheduler = optim.lr_scheduler.StepLR(optimizer[0], 1, gamma=0.5, last_epoch=-1)\n  epoch = 0 #epochs done so far\n  stopf = False #status to know when to stop\n  stoparr=[False,False,False,False]\n  prev_loss=[9999,9999,9999,9999]\n\n  while not stopf:\n    train_running_loss_nor = 0.0\n    train_running_acc_nor = 0.0\n    train_running_loss_se = 0.0\n    train_running_acc_se = 0.0\n    train_running_loss_cbam = 0.0\n    train_running_acc_cbam = 0.0\n    train_running_loss_eca = 0.0\n    train_running_acc_eca = 0.0\n    \n\n    val_running_loss_nor = 0.0\n    val_running_acc_nor = 0.0\n    val_running_loss_se = 0.0\n    val_running_acc_se = 0.0\n    val_running_loss_cbam = 0.0\n    val_running_acc_cbam = 0.0\n    val_running_loss_eca = 0.0\n    val_running_acc_eca = 0.0\n    \n    train_running_loss=[train_running_loss_nor,train_running_loss_se,train_running_loss_cbam,train_running_loss_eca]\n    train_running_acc=[train_running_acc_nor,train_running_acc_se,train_running_acc_cbam,train_running_acc_eca]\n\n    val_running_loss=[val_running_loss_nor,val_running_loss_se,val_running_loss_cbam,val_running_loss_eca]\n    val_running_acc=[val_running_acc_nor,val_running_acc_se,val_running_acc_cbam,val_running_acc_eca]\n    for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n      sample = extract_sample(n_way, n_support, n_query, train_x, train_y)\n      \n      for i in range(len(model)): \n        optimizer[i].zero_grad()\n        loss, output = model[i].set_forward_loss(sample)\n        train_running_loss[i] += output['loss']\n        train_running_acc[i] += output['acc']\n        loss.backward()\n        optimizer[i].step()\n    for episode in tnrange(epoch_size):\n      sample = extract_sample(n_way, n_support, n_query, val_x, val_y)\n      for i in range(len(model)):\n        loss, output = model[i].set_forward_loss(sample)\n        val_running_loss[i] += output['loss']\n        val_running_acc[i] += output['acc']\n    for i in range(len(model)):\n      avg_loss = val_running_loss[i] / epoch_size\n      avg_acc = val_running_acc[i] / epoch_size\n      print('Validation results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n      if(prev_loss[i]-avg_loss<=0.01):\n        print(\"Validation loss plateus for model\",i)\n        stoparr[i]=True\n        temp=True\n        for i in stoparr:\n          if i==False:\n            temp=False\n        if temp==True:\n          stopf=True\n          break\n      prev_loss[i]=avg_loss\n      \n    for i in range(len(model)):\n      epoch_loss = train_running_loss[i] / epoch_size\n      epoch_acc = train_running_acc[i] / epoch_size\n      print('Training Results: Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n    epoch += 1\n    scheduler.step()\n  ","metadata":{"id":"9tHY4lOoW58K","execution":{"iopub.status.busy":"2022-06-25T13:46:35.186496Z","iopub.execute_input":"2022-06-25T13:46:35.187508Z","iopub.status.idle":"2022-06-25T13:46:35.206324Z","shell.execute_reply.started":"2022-06-25T13:46:35.187468Z","shell.execute_reply":"2022-06-25T13:46:35.205239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pass\ndef test_MIN(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n  \"\"\"\n  Tests the protonet\n  Args:\n      model: trained model\n      test_x (np.array): images of testing set\n      test_y (np.array): labels of testing set\n      n_way (int): number of classes in a classification task\n      n_support (int): number of labeled examples per class in the support set\n      n_query (int): number of labeled examples per class in the query set\n      test_episode (int): number of episodes to test on\n  \"\"\"\n    running_loss18 = 0.0\n    running_acc18 = 0.0\n    running_loss34 = 0.0\n    running_acc34 = 0.0\n    running_loss101 = 0.0\n    running_acc101 = 0.0\n    running_loss152 = 0.0\n    running_acc152 = 0.0\n\n    running_loss=[running_loss18,running_loss34,running_loss101,running_loss152]\n    running_acc=[running_acc18,running_acc34,running_acc101,running_acc152]\n  for episode in tnrange(test_episode):\n    sample = extract_sample(n_way, n_support, n_query, test_x, test_y)\n    for i in range(len(model)):\n      loss, output = model[i].set_forward_loss(sample)\n      running_loss[i] += output['loss']\n      running_acc[i] += output['acc']\n  for i in range(len(model)):\n    avg_loss = running_loss[i] / test_episode\n    avg_acc = running_acc[i] / test_episode\n    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))","metadata":{"id":"GYmBa6QlkPA4","outputId":"2e38861f-1b14-4c1b-c54f-a36258f27c77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pass\ndef train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size):\n  \"\"\"\n  Trains the protonet\n  Args:\n      model\n      optimizer\n      train_x (np.array): images of training set\n      train_y(np.array): labels of training set\n      n_way (int): number of classes in a classification task\n      n_support (int): number of labeled examples per class in the support set\n      n_query (int): number of labeled examples per class in the query set\n      max_epoch (int): max epochs to train on\n      epoch_size (int): episodes per epoch\n  \"\"\"\n  #divide the learning rate by 2 at each epoch, as suggested in paper\n  scheduler = optim.lr_scheduler.StepLR(optimizer[0], 1, gamma=0.5, last_epoch=-1)\n  epoch = 0 #epochs done so far\n  stop = False #status to know when to stop\n\n  while epoch < max_epoch and not stop:\n    running_loss18 = 0.0\n    running_acc18 = 0.0\n    running_loss34 = 0.0\n    running_acc34 = 0.0\n    running_loss101 = 0.0\n    running_acc101 = 0.0\n    running_loss152 = 0.0\n    running_acc152 = 0.0\n    \n    running_loss=[running_loss18,running_loss34,running_loss101,running_loss152]\n    running_acc=[running_acc18,running_acc34,running_acc101,running_acc152]\n    for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n      sample = extract_sample(n_way, n_support, n_query, train_x, train_y)\n      \n      for i in range(len(model)): \n        optimizer[i].zero_grad()\n        loss, output = model[i].set_forward_loss(sample)\n        running_loss[i] += output['loss']\n        running_acc[i] += output['acc']\n        loss.backward()\n        optimizer[i].step()\n    for i in range(len(model)):\n      epoch_loss = running_loss[i] / epoch_size\n      epoch_acc = running_acc[i] / epoch_size\n      print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n    epoch += 1\n    scheduler.step()","metadata":{"id":"mY5nYWryb8Or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model18 = load_protonet_conv(arg=18)\n#model34 = load_protonet_conv(arg=34)\n#model101 = load_protonet_conv(arg=101)\n#model152 = load_protonet_conv(arg=152)\n\nmodel_nor_5=load_protonet_conv(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_se_5=load_protonet_conv_se(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_cbam_5=load_protonet_conv_cbam(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_eca_5=load_protonet_conv_eca(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\n\noptimizer_nor = optim.Adam(model_nor_5.parameters(), lr = 0.001)\noptimizer_se = optim.Adam(model_se_5.parameters(), lr = 0.001)\noptimizer_cbam = optim.Adam(model_cbam_5.parameters(), lr = 0.001)\noptimizer_eca = optim.Adam(model_eca_5.parameters(), lr = 0.001)\n\nmodel_5=[model_nor_5,model_se_5,model_cbam_5,model_eca_5]\noptimizer_5=[optimizer_nor,optimizer_se,optimizer_cbam,optimizer_eca]\n\nn_way = 20\nn_support = 5\nn_query = 15\n\ntrain_x = trainx\ntrain_y = trainy\n\nval_x=valx\nval_y=valy\n\n#max_epoch = 5\n#epoch_size = 2000\n\nmax_epoch = 5\nepoch_size = 1000\n","metadata":{"id":"CI5O7N9ab-hz","execution":{"iopub.status.busy":"2022-06-25T13:56:06.97432Z","iopub.execute_input":"2022-06-25T13:56:06.975389Z","iopub.status.idle":"2022-06-25T13:56:07.003798Z","shell.execute_reply.started":"2022-06-25T13:56:06.975341Z","shell.execute_reply":"2022-06-25T13:56:07.002756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_MIN(model_5, optimizer_5, train_x, train_y,val_x,val_y, n_way, n_support, n_query, epoch_size)","metadata":{"id":"WS16R4tV-mc-","outputId":"a66fa8b4-a753-471d-f030-5483c592300d","execution":{"iopub.status.busy":"2022-06-25T13:56:09.826039Z","iopub.execute_input":"2022-06-25T13:56:09.826697Z","iopub.status.idle":"2022-06-25T14:27:53.960049Z","shell.execute_reply.started":"2022-06-25T13:56:09.826661Z","shell.execute_reply":"2022-06-25T14:27:53.959075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model18 = load_protonet_conv(arg=18)\n#model34 = load_protonet_conv(arg=34)\n#model101 = load_protonet_conv(arg=101)\n#model152 = load_protonet_conv(arg=152)\n\nmodel_nor_1=load_protonet_conv(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_se_1=load_protonet_conv_se(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_cbam_1=load_protonet_conv_cbam(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\nmodel_eca_1=load_protonet_conv_eca(x_dim=(3,40,40),\n    hid_dim=64,\n    z_dim=64,)\n\noptimizer_nor = optim.Adam(model_nor_1.parameters(), lr = 0.001)\noptimizer_se = optim.Adam(model_se_1.parameters(), lr = 0.001)\noptimizer_cbam = optim.Adam(model_cbam_1.parameters(), lr = 0.001)\noptimizer_eca = optim.Adam(model_eca_1.parameters(), lr = 0.001)\n\nmodel_1=[model_nor_1,model_se_1,model_cbam_1,model_eca_1]\noptimizer_1=[optimizer_nor,optimizer_se,optimizer_cbam,optimizer_eca]\n\nn_way = 30\nn_support = 1\nn_query = 15\n\ntrain_x = trainx\ntrain_y = trainy\n\nval_x=valx\nval_y=valy\n\n#max_epoch = 5\n#epoch_size = 2000\n\nmax_epoch = 5\nepoch_size = 1000\n","metadata":{"id":"37DUP1hy-WFX","execution":{"iopub.status.busy":"2022-06-25T14:29:01.871601Z","iopub.execute_input":"2022-06-25T14:29:01.871962Z","iopub.status.idle":"2022-06-25T14:29:01.9008Z","shell.execute_reply.started":"2022-06-25T14:29:01.871914Z","shell.execute_reply":"2022-06-25T14:29:01.899835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_MIN(model_1, optimizer_1, train_x, train_y,val_x,val_y, n_way, n_support, n_query, epoch_size)","metadata":{"id":"YxP0YDzi-qzw","outputId":"bbe5887e-963e-4295-ae3b-cb7f379aa7bf","execution":{"iopub.status.busy":"2022-06-25T14:29:04.490328Z","iopub.execute_input":"2022-06-25T14:29:04.490773Z","iopub.status.idle":"2022-06-25T15:30:26.615746Z","shell.execute_reply.started":"2022-06-25T14:29:04.490733Z","shell.execute_reply":"2022-06-25T15:30:26.61301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n  \"\"\"\n  Tests the protonet\n  Args:\n      model: trained model\n      test_x (np.array): images of testing set\n      test_y (np.array): labels of testing set\n      n_way (int): number of classes in a classification task\n      n_support (int): number of labeled examples per class in the support set\n      n_query (int): number of labeled examples per class in the query set\n      test_episode (int): number of episodes to test on\n  \"\"\"\n  running_loss_nor = 0.0\n  running_acc_nor = 0.0\n  running_loss_se = 0.0\n  running_acc_se = 0.0\n  running_loss_cbam = 0.0\n  running_acc_cbam = 0.0\n  running_loss_eca = 0.0\n  running_acc_eca = 0.0\n\n  running_loss=[running_loss_nor,running_loss_se,running_loss_nor,running_loss_se]\n  running_acc=[running_acc_nor,running_acc_se,running_acc_nor,running_acc_se]\n  for episode in tnrange(test_episode):\n    sample = extract_sample(n_way, n_support, n_query, test_x, test_y)\n    for i in range(len(model)):\n      loss, output = model[i].set_forward_loss(sample)\n      running_loss[i] += output['loss']\n      running_acc[i] += output['acc']\n  for i in range(len(model)):\n    avg_loss = running_loss[i] / test_episode\n    avg_acc = running_acc[i] / test_episode\n    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))","metadata":{"id":"vW55yKPtcCXr","execution":{"iopub.status.busy":"2022-06-25T15:30:38.744622Z","iopub.execute_input":"2022-06-25T15:30:38.744989Z","iopub.status.idle":"2022-06-25T15:30:38.755393Z","shell.execute_reply.started":"2022-06-25T15:30:38.744952Z","shell.execute_reply":"2022-06-25T15:30:38.754293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###5 way 5 shot","metadata":{"id":"2zV-4hQE_LPm"}},{"cell_type":"code","source":"n_way = 5\nn_support = 5\nn_query = 15\n\ntest_x = testx\ntest_y = testy\n\ntest_episode = 1000\n\ntest(model_5, test_x, test_y, n_way, n_support, n_query, test_episode)","metadata":{"id":"kFO9tpIxcEk5","outputId":"fa4a0898-e603-4383-cde7-53aa4f5b67b5","execution":{"iopub.status.busy":"2022-06-25T15:34:24.925384Z","iopub.execute_input":"2022-06-25T15:34:24.925731Z","iopub.status.idle":"2022-06-25T15:34:53.901105Z","shell.execute_reply.started":"2022-06-25T15:34:24.925702Z","shell.execute_reply":"2022-06-25T15:34:53.90001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###20 Way 5 shot","metadata":{"id":"sF7bJTXc_XWo"}},{"cell_type":"code","source":"n_way = 20\nn_support = 5\nn_query = 15\n\ntest_x = testx\ntest_y = testy\n\ntest_episode = 1000\n\ntest(model_5, test_x, test_y, n_way, n_support, n_query, test_episode)","metadata":{"id":"-xFsu7BA_UiC","outputId":"c7821801-f7b2-40a5-80ab-2260f83eb202","execution":{"iopub.status.busy":"2022-06-25T15:34:53.904585Z","iopub.execute_input":"2022-06-25T15:34:53.905831Z","iopub.status.idle":"2022-06-25T15:36:33.899416Z","shell.execute_reply.started":"2022-06-25T15:34:53.905745Z","shell.execute_reply":"2022-06-25T15:36:33.89844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-2Z3iX0wnRcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###5 way 1 shot","metadata":{"id":"pPg0z4Gl_b0R"}},{"cell_type":"code","source":"n_way = 5\nn_support = 1\nn_query = 15\n\ntest_x = testx\ntest_y = testy\n\ntest_episode = 1000\n\ntest(model_1, test_x, test_y, n_way, n_support, n_query, test_episode)","metadata":{"outputId":"857d84f3-abc0-4885-bba1-d217f056d61e","id":"gmhqrryt_b0R","execution":{"iopub.status.busy":"2022-06-25T15:36:33.900956Z","iopub.execute_input":"2022-06-25T15:36:33.901977Z","iopub.status.idle":"2022-06-25T15:36:58.681088Z","shell.execute_reply.started":"2022-06-25T15:36:33.90192Z","shell.execute_reply":"2022-06-25T15:36:58.680097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###20 Way 1 shot","metadata":{"id":"7FRpoq4P_b0S"}},{"cell_type":"code","source":"n_way = 20\nn_support = 1\nn_query = 15\n\ntest_x = testx\ntest_y = testy\n\ntest_episode = 1000\n\ntest(model_1, test_x, test_y, n_way, n_support, n_query, test_episode)","metadata":{"id":"CnKXp016_b0T","outputId":"4e0ba91c-2fd3-41fe-d987-28123ce3c67b","execution":{"iopub.status.busy":"2022-06-25T15:36:58.683372Z","iopub.execute_input":"2022-06-25T15:36:58.685225Z","iopub.status.idle":"2022-06-25T15:38:33.534945Z","shell.execute_reply.started":"2022-06-25T15:36:58.685179Z","shell.execute_reply":"2022-06-25T15:38:33.53386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LiLUO5LMj30j"},"execution_count":null,"outputs":[]}]}